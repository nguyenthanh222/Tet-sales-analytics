# -*- coding: utf-8 -*-
"""PhÃ¢n TÃ­ch & Dá»± BÃ¡o Kinh Doanh Táº¿t 2026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YlPSbpdjCy2hZ0NWWLTWTzVQgPGtxee_
"""

pip install faker pandas numpy

import pandas as pd
from faker import Faker
import random
from datetime import datetime, timedelta

fake = Faker(['vi_VN'])
Faker.seed(42)

# --- 1. Dim_Customers (TÄƒng lÃªn 500 khÃ¡ch hÃ ng cho Ä‘a dáº¡ng) ---
num_customers = 500
customers = []
for _ in range(num_customers):
    customers.append({
        'CustomerID': fake.unique.random_int(min=10000, max=99999),
        'CustomerName': fake.name(),
        'City': random.choice(['HÃ  Ná»™i', 'TP. Há»“ ChÃ­ Minh', 'ÄÃ  Náºµng', 'Cáº§n ThÆ¡', 'Háº£i PhÃ²ng']),
        'Segment': random.choice(['VIP', 'Loyal', 'New', 'Potential'])
    })
dim_customers = pd.DataFrame(customers)

# --- 2. Dim_Products ---
products_data = [
    ('T01', 'Giá» quÃ  XuÃ¢n NhÆ° Ã', 'Giá» quÃ ', 550000),
    ('T02', 'BÃ¡nh chÆ°ng náº¿p nÆ°Æ¡ng', 'Äá»“ cÃºng', 120000),
    ('B01', 'ThÃ¹ng Bia 24 lon', 'NÆ°á»›c giáº£i khÃ¡t', 380000),
    ('K01', 'Má»©t dá»«a Báº¿n Tre', 'BÃ¡nh káº¹o', 85000),
    ('G01', 'Bá»™ bÃ¡t Ä‘Ä©a gá»‘m sá»©', 'Gia dá»¥ng', 450000)
]
dim_products = pd.DataFrame(products_data, columns=['SKU', 'ProductName', 'Category', 'Price'])

# --- 3. Fact_Sales (Táº¡o 1000 dÃ²ng giao dá»‹ch) ---
sales = []
total_rows = 1000
start_date = datetime(2025, 12, 1)
end_date = datetime(2026, 2, 15)

# Äá»‹nh nghÄ©a cÃ¡c má»‘c thá»i gian Táº¿t theo hÃ¬nh sá»‘ 5 báº¡n gá»­i
pre_tet_start = datetime(2026, 1, 15)
pre_tet_end = datetime(2026, 1, 28)
tet_days = [datetime(2026, 1, 29), datetime(2026, 1, 30), datetime(2026, 1, 31)]

for _ in range(total_rows):
    # Chá»n ngÃ y ngáº«u nhiÃªn nhÆ°ng Æ°u tiÃªn dá»“n vÃ o giai Ä‘oáº¡n Pre-Tet Ä‘á»ƒ mÃ´ phá»ng mÃ¹a vá»¥
    if random.random() < 0.6: # 60% dá»¯ liá»‡u rÆ¡i vÃ o Pre-Tet
        order_date = fake.date_between_dates(date_start=pre_tet_start, date_end=pre_tet_end)
    else:
        order_date = fake.date_between_dates(date_start=start_date, date_end=end_date)

    # Ã‰p kiá»ƒu vá» datetime Ä‘á»ƒ so sÃ¡nh
    order_date = datetime.combine(order_date, datetime.min.time())

    prod = dim_products.sample(1).iloc[0]

    # Logic sá»‘ lÆ°á»£ng: Pre-Tet mua nhiá»u hÆ¡n (giá» quÃ , bia)
    if pre_tet_start <= order_date <= pre_tet_end:
        qty = random.randint(3, 15) if prod['Category'] in ['Giá» quÃ ', 'NÆ°á»›c giáº£i khÃ¡t'] else random.randint(1, 5)
    elif order_date in tet_days:
        qty = random.randint(1, 2) # NgÃ y Táº¿t bÃ¡n ráº¥t Ã­t
    else:
        qty = random.randint(1, 3)

    sales.append({
        'OrderID': fake.unique.bothify(text='INV-######'),
        'OrderDate': order_date,
        'CustomerID': random.choice(dim_customers['CustomerID'].values),
        'SKU': prod['SKU'],
        'Quantity': qty,
        'TotalAmount': qty * prod['Price'],
        'Channel': random.choice(['Shopee', 'Lazada', 'Facebook', 'Offline Store']),
        'Region': random.choice(['Miá»n Báº¯c', 'Miá»n Trung', 'Miá»n Nam'])
    })

fact_sales = pd.DataFrame(sales).sort_values('OrderDate')
print(f"ÄÃ£ táº¡o xong {len(fact_sales)} dÃ²ng dá»¯ liá»‡u giao dá»‹ch!")

import sqlite3

# 1. Káº¿t ná»‘i file database
conn = sqlite3.connect('tet_sales_warehouse.db')

# 2. LÆ°u cÃ¡c DataFrame  vÃ o cÃ¡c báº£ng SQL
fact_sales.to_sql('fact_sales', conn, if_exists='replace', index=False)
dim_customers.to_sql('dim_customers', conn, if_exists='replace', index=False)
dim_products.to_sql('dim_products', conn, if_exists='replace', index=False)

print("ÄÃ£ lÆ°u 1.000 dÃ²ng vÃ o Data Warehouse SQLite!")

# Truy váº¥n
query_metrics = """
SELECT
    COUNT(DISTINCT OrderID) as Total_Orders,
    SUM(TotalAmount) as GMV,
    SUM(TotalAmount) / COUNT(DISTINCT OrderID) as AOV
FROM fact_sales;
"""

metrics_df = pd.read_sql(query_metrics, conn)
print(metrics_df)

query_sku_analysis = """
SELECT
    SKU,
    SUM(TotalAmount) as SKU_GMV,
    (SUM(TotalAmount) * 100.0 / (SELECT SUM(TotalAmount) FROM fact_sales)) as Contribution_Percentage
FROM fact_sales
GROUP BY SKU
ORDER BY SKU_GMV DESC;
"""

sku_analysis = pd.read_sql(query_sku_analysis, conn)
print(sku_analysis)

import gradio as gr
import pandas as pd
import sqlite3
import os
from datetime import timedelta

# Äáº£m báº£o Ä‘Æ°á»ng dáº«n file database chÃ­nh xÃ¡c khi cháº¡y trÃªn server
DB_PATH = "tet_sales_warehouse.db"

def get_comprehensive_analytics(region_filter):
    # Kiá»ƒm tra náº¿u file DB tá»“n táº¡i
    if not os.path.exists(DB_PATH):
        return None, None, None, None, None

    conn = sqlite3.connect(DB_PATH)
    where_clause = "" if region_filter == "Táº¥t cáº£" else f"WHERE f.Region = '{region_filter}'"

    # 1. Hiá»‡u suáº¥t Sáº£n pháº©m & Danh má»¥c
    df_sku = pd.read_sql(f"""
        SELECT p.ProductName, p.Category, SUM(f.TotalAmount) as GMV
        FROM fact_sales f
        JOIN dim_products p ON f.SKU = p.SKU
        {where_clause}
        GROUP BY p.ProductName, p.Category ORDER BY GMV DESC
    """, conn)

    # 2. Xu hÆ°á»›ng & Dá»± bÃ¡o
    df_trend = pd.read_sql(f"""
        SELECT OrderDate, SUM(TotalAmount) as Daily_Sales
        FROM fact_sales f {where_clause}
        GROUP BY OrderDate ORDER BY OrderDate
    """, conn)
    df_trend['OrderDate'] = pd.to_datetime(df_trend['OrderDate'])

    # Logic Dá»± bÃ¡o 7 ngÃ y
    avg_recent = df_trend['Daily_Sales'].tail(7).mean()
    last_date = df_trend['OrderDate'].max()
    forecast_list = []
    for i in range(1, 8):
        forecast_list.append({
            'OrderDate': last_date + timedelta(days=i),
            'Daily_Sales': avg_recent * (1.05 ** i),
            'Type': 'Dá»± bÃ¡o'
        })
    df_forecast = pd.DataFrame(forecast_list)
    df_actual = df_trend.copy(); df_actual['Type'] = 'Thá»±c táº¿'
    df_combined_trend = pd.concat([df_actual, df_forecast])

    # 3. So sÃ¡nh Khu vá»±c
    df_region = pd.read_sql("SELECT Region, SUM(TotalAmount) as GMV FROM fact_sales GROUP BY Region", conn)

    # 4. Tá»“n kho DOS
    df_inv = pd.read_sql(f"""
        SELECT p.ProductName, SUM(f.Quantity) as Sold, (2000 - SUM(f.Quantity)) as On_Hand
        FROM fact_sales f JOIN dim_products p ON f.SKU = p.SKU
        GROUP BY p.ProductName
    """, conn)
    df_inv['DOS'] = df_inv['On_Hand'] / (df_inv['Sold'].replace(0, 1) / 45)

    conn.close()
    return df_combined_trend, df_region, df_sku, df_sku, df_inv

# Giao diá»‡n Blocks
with gr.Blocks(title="ğŸ§§ Há»‡ Thá»‘ng Quáº£n Trá»‹ Táº¿t") as demo:
    gr.Markdown("# ğŸ§§ Dashboard PhÃ¢n TÃ­ch & Dá»± BÃ¡o Kinh Doanh Táº¿t 2026")
    region_dropdown = gr.Dropdown(choices=["Táº¥t cáº£", "Miá»n Báº¯c", "Miá»n Trung", "Miá»n Nam"], value="Táº¥t cáº£", label="ğŸ“ Lá»c theo Khu vá»±c")

    with gr.Tab("ğŸ“ˆ Xu HÆ°á»›ng & Dá»± BÃ¡o"):
        forecast_plot = gr.LinePlot(x="OrderDate", y="Daily_Sales", color="Type", title="BÃ¡o cÃ¡o Xu hÆ°á»›ng & Dá»± bÃ¡o", width=900)

    with gr.Tab("ğŸ“Š Hiá»‡u Suáº¥t Sáº£n Pháº©m"):
        with gr.Row():
            sku_plot = gr.BarPlot(x="ProductName", y="GMV", color="Category", title="GMV theo Sáº£n pháº©m", vertical=False)
            sku_table = gr.DataFrame(label="Chi tiáº¿t Danh má»¥c")

    with gr.Row():
        region_plot = gr.BarPlot(x="Region", y="GMV", title="GMV theo Miá»n", color="Region")
        dos_plot = gr.BarPlot(x="ProductName", y="DOS", title="Sá»‘ ngÃ y Ä‘á»§ bÃ¡n dá»± kiáº¿n", color="ProductName")

    region_dropdown.change(get_comprehensive_analytics, inputs=[region_dropdown], outputs=[forecast_plot, region_plot, sku_plot, sku_table, dos_plot])
    demo.load(get_comprehensive_analytics, inputs=[region_dropdown], outputs=[forecast_plot, region_plot, sku_plot, sku_table, dos_plot])

# KhÃ´ng dÃ¹ng share=True khi deploy lÃªn Hugging Face
if __name__ == "__main__":
    demo.launch()